{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3efeacdb",
   "metadata": {},
   "source": [
    "Date: 20230419  \n",
    "Model_Selection  \n",
    "\n",
    "想法：最近实习跑数据模型，觉得一个个数据和一个个模型的输入跑，太浪费时间，且很混乱，就写了个类来规整一下，昨天觉得有必要以后都这样规范的写，所以这里做个备份  \n",
    "\n",
    "大抵构思为：DataModel类存储数据集，并保存必要信息，然后可以定义一系列的数据处理函数，以及模型fit函数，以及各具体模型的fit函数，由modelname属性来判断是要拟合哪个模型，并输入对应参数，这样就可以很方便的对于不同数据，不同模型拟合，并很好的展示其测试结果。  \n",
    "然后使用了帖子https://blog.csdn.net/qq_52466006/article/details/127633149 定义的多分类的报告类，并稍作修改，用以展示测试结果，比如多分类的混淆矩阵，accuracy  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f8c53429",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# XGB\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import auc, roc_auc_score, roc_curve, f1_score, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# SVM\n",
    "import numpy as np                   \n",
    "from sklearn import svm            \n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# 全连接 softmax dropout，这里的神经网络是课程作业设置的简单的全连接网络，还需后续再改下代码整洁度，并嵌入DataModel类中\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "\n",
    "# softmax\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# 训练随机森林解决回归问题\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# lgbm\n",
    "import lightgbm as lgb\n",
    "from lightgbm import LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9ee6ce1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FCsoftmax(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(FCsoftmax, self).__init__()\n",
    "        self.block = nn.Sequential(\n",
    "            nn.Linear(input_dim, 32), nn.Dropout(p=0.5), nn.ReLU(),\n",
    "            nn.Linear(32, 64), nn.Dropout(p=0.5), nn.ReLU(),\n",
    "            nn.Linear(64, 128), nn.Dropout(p=0.5), nn.ReLU(),\n",
    "            nn.Linear(128, 64), nn.Dropout(p=0.5), nn.ReLU(),\n",
    "            nn.Linear(64, 32), nn.Dropout(p=0.5), nn.ReLU(),\n",
    "            nn.Linear(32, 3), nn.Softmax(dim=1))  # 需指明dim维度，不然会warning\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.block(x)\n",
    "        return x\n",
    "\n",
    "def train(model, optimizer, lossfunction, x, y):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    output = model(x)\n",
    "    loss = lossfunction(output, y)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss.item()  #转为标量浮点值\n",
    "\n",
    "def Fnn(X_train, X_test, y_train):\n",
    "    torch.manual_seed(1)  # 使用随机化种子使神经网络的初始化每次都相同\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    train_x = torch.tensor(X_train.values, dtype=torch.float32).cuda()\n",
    "    train_y = torch.tensor(y_train.to_numpy()[:,np.newaxis] == np.arange(3), dtype=torch.float32).cuda()  # 转为onehot\n",
    "    \n",
    "    x_test = torch.tensor(X_test.values, dtype=torch.float32)\n",
    "    \n",
    "    input_dim = train_x.shape[1]\n",
    "    n_epochs = 1000 # 经由初步筛选避免过拟合后的次数\n",
    "    lossfunction = nn.CrossEntropyLoss().cuda()\n",
    "    model = FCsoftmax(input_dim)\n",
    "    model.to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        trainloss = train(model, optimizer, lossfunction, train_x, train_y)\n",
    "\n",
    "        if (epoch+1) % 100 == 0:\n",
    "            print('epoch:{} loss:{}'.format(epoch+1,trainloss))\n",
    "    \n",
    "    model.eval()\n",
    "    model.to('cpu')\n",
    "    \n",
    "    #predictions from test data\n",
    "    inputs = x_test \n",
    "    test_output = model(inputs)\n",
    "    \n",
    "    pred_y = torch.max(test_output, 1)[1].data.numpy()\n",
    "    return pred_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "628e747f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Myreport:\n",
    "    def __init__(self):\n",
    "        self.confusion = None\n",
    "\n",
    "    def statistics_confusion(self,y_true,y_predict):\n",
    "        self.confusion = np.zeros((3,3))\n",
    "        for i in range(y_true.shape[0]):\n",
    "            self.confusion[int(y_predict[i])][int(y_true[i])] += 1\n",
    "\n",
    "    def __cal_Acc(self):\n",
    "        return np.sum(self.confusion.diagonal()) / np.sum(self.confusion)\n",
    "\n",
    "    def __cal_Pc(self):\n",
    "        return self.confusion.diagonal() / np.sum(self.confusion, axis=1)\n",
    "\n",
    "    def __cal_Rc(self):\n",
    "        return self.confusion.diagonal() / np.sum(self.confusion, axis=0)\n",
    "\n",
    "    def __cal_F1score(self,PC,RC):\n",
    "        return 2 * np.multiply(PC, RC) / (PC + RC)\n",
    "\n",
    "    def report(self,y_true,y_predict,classNames):\n",
    "        self.statistics_confusion(y_true,y_predict)\n",
    "        Acc = self.__cal_Acc()\n",
    "        Pc = self.__cal_Pc()\n",
    "        Rc = self.__cal_Rc()\n",
    "        F1score = self.__cal_F1score(Pc,Rc)\n",
    "        str = \"Class Name\\t\\tprecision\\t\\trecall\\t\\tf1-score\\n\"\n",
    "        for i in range(len(classNames)):\n",
    "           str += f\"{classNames[i]}   \\t\\t\\t{format(Pc[i],'.2f')}   \\t\\t\\t{format(Rc[i],'.2f')}\" \\\n",
    "                  f\"   \\t\\t\\t{format(F1score[i],'.2f')}\\n\"\n",
    "        str += f\"accuracy is {format(Acc,'.2f')}\"\n",
    "        return str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ebc1e271",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Datamodel:\n",
    "    def __init__(self, data_name, model_name):\n",
    "        self.data = None\n",
    "        self.label = None\n",
    "        self.X_train = None\n",
    "        self.X_test = None\n",
    "        self.y_train = None\n",
    "        self.y_test = None\n",
    "        self.y_pred = None\n",
    "        self.data_name = data_name\n",
    "        self.confusion = None\n",
    "#         self.Report = None\n",
    "        self.pcrc = None\n",
    "        self.modelname = model_name\n",
    "        \n",
    "    def data_read(self, path, label):\n",
    "        self.label = label\n",
    "        self.data = pd.read_csv(path, header=0)\n",
    "        self.data = self.data[['ask1', 'bid1', 'asize1', 'bsize1', 'spread', 'mid_price', 'micro_price', 'dPa', 'dPb', 'dPmicro', 'OFI','LogquoteSlope1_new', 'SOIR1', 'MPC1', 'MPC5', 'label_next5', 'label_next10', 'label_next20']]\n",
    "        self.data = self.data.dropna()\n",
    "        self.data['label_next5'] = self.data['label_next5']+1\n",
    "        self.data['label_next10'] = self.data['label_next10']+1\n",
    "        self.data['label_next20'] = self.data['label_next20']+1  \n",
    "        \n",
    "    def sample_balance(self):\n",
    "        sample_balance_index = self.data[self.data[self.label]==1].index\n",
    "        # 对序列随机排序\n",
    "#         np.random.seed(20303)\n",
    "        indices_random = np.random.permutation(sample_balance_index)\n",
    "                \n",
    "        # 随机抽取与label_next5==+-1的总个数两倍作为样本平衡\n",
    "        pnum = self.data[self.data[self.label]==2].shape[0]\n",
    "        nnum = self.data[self.data[self.label]==0].shape[0]\n",
    "        \n",
    "        zero_index = pd.Index(indices_random[:int(np.floor(0.5*(pnum+nnum)))])\n",
    "        p_index = self.data[self.data[self.label]==2].index\n",
    "        n_index = self.data[self.data[self.label]==0].index\n",
    "\n",
    "        balance_index=zero_index.append(n_index.append(p_index))\n",
    "        balance_index = [i for i in balance_index if i < self.data.shape[0]]\n",
    "        self.data = self.data.iloc[balance_index[:],:]   \n",
    "    \n",
    "    def data_split(self):\n",
    "        # split data into features and target，label_next5-20为预测的target\n",
    "        X = self.data.drop(['label_next5', 'label_next10', 'label_next20'], axis=1)\n",
    "        y = self.data[self.label] # choose any of the target variables to train on\n",
    "        \n",
    "        # split into train and test sets\n",
    "#         这里因为是时序数据所以直接按时间顺序分为测试集训练集，可以随机分，或进一步分出验证集\n",
    "        lenth = X.shape[0]\n",
    "        self.X_train = X[:int(np.floor(lenth*0.8))].reset_index(drop=True)\n",
    "        self.X_test = X[int(np.floor(lenth*0.8)):].reset_index(drop=True)\n",
    "        self.y_train = y[:int(np.floor(lenth*0.8))].reset_index(drop=True)\n",
    "        self.y_test = y[int(np.floor(lenth*0.8)):].reset_index(drop=True)\n",
    "                \n",
    "    def XGBoost(self, booster):\n",
    "        '''\n",
    "        booster: 'gblinear','gbtree'\n",
    "        '''\n",
    "        model = xgb.XGBClassifier(booster=booster, n_estimators=1000, learning_rate=0.05, objective='multi:softmax', num_class=3)\n",
    "        model.fit(self.X_train, self.y_train)\n",
    "        self.y_pred = model.predict(self.X_test)\n",
    "        \n",
    "    def SVM(self, C, k):\n",
    "        '''\n",
    "        kernel == 'linear','rbf','sigmoid'\n",
    "        '''\n",
    "        model = svm.SVC(C=C,                         #误差项惩罚系数,默认值是1\n",
    "                        kernel=k,               #线性核 kenrel=\"rbf\":高斯核\n",
    "                        class_weight='balanced',\n",
    "                        decision_function_shape='ovr') #决策函数\n",
    "        model.fit(self.X_train, self.y_train)\n",
    "        self.y_pred = model.predict(self.X_test)\n",
    "        \n",
    "    def FC(self):\n",
    "        self.y_pred = Fnn(self.X_train, self.X_test, self.y_train)\n",
    "    \n",
    "    def softmax(self):\n",
    "        '''\n",
    "        softmax regression\n",
    "        '''\n",
    "        classifier = LogisticRegression()\n",
    "        classifier.fit(self.X_train, self.y_train)\n",
    "        self.y_pred = classifier.predict(self.X_test)\n",
    "\n",
    "    def knn(self):\n",
    "        knn = KNeighborsClassifier()    #实例化KNN模型\n",
    "        knn.fit(self.X_train, self.y_train) \n",
    "        self.y_pred = knn.predict(self.X_test)\n",
    "        \n",
    "        \n",
    "    def randomforest(self, n_estimator):\n",
    "        regressor = RandomForestRegressor(n_estimators=n_estimator, random_state=0, bootstrap=True)\n",
    "#         因样本量太小，所以尝试使用bootstrap\n",
    "        regressor.fit(self.X_train, self.y_train)\n",
    "        self.y_pred = regressor.predict(self.X_test)\n",
    "        \n",
    "    def lgbm(self):\n",
    "        model = LGBMClassifier(\n",
    "                max_depth=3,\n",
    "                learning_rate=0.1,\n",
    "                n_estimators=200, # 使用多少个弱分类器\n",
    "                objective='multiclass',\n",
    "                num_class=3,\n",
    "                booster='gbtree',\n",
    "                min_child_weight=2,\n",
    "                subsample=0.8,\n",
    "                colsample_bytree=0.8,\n",
    "                reg_alpha=0,\n",
    "                reg_lambda=1,\n",
    "                seed=0 # 随机数种子\n",
    "                )\n",
    "        model.fit(self.X_train,self.y_train, eval_set=[(self.X_train, self.y_train), (self.X_test, self.y_test)], \n",
    "              verbose=100, early_stopping_rounds=50)\n",
    "\n",
    "        # 对测试集进行预测\n",
    "        self.y_pred = model.predict(self.X_test)\n",
    "\n",
    "    def model_fit(self, *args, **kwargs):\n",
    "        '''\n",
    "        modelname = 'XGBoost','SVM','FC','softmaxregression','knn','randomforest','lightgbm'\n",
    "        '''\n",
    "        if self.modelname == 'XGBoost':\n",
    "            self.XGBoost(*args, **kwargs)\n",
    "        elif self.modelname == 'SVM':\n",
    "            self.SVM(*args, **kwargs)\n",
    "        elif self.modelname == 'FC':\n",
    "            self.FC(*args, **kwargs)\n",
    "        elif self.modelname == 'softmaxregression':\n",
    "            self.softmax(*args, **kwargs)\n",
    "        elif self.modelname == 'knn':\n",
    "            self.knn(*args, **kwargs)\n",
    "        elif self.modelname == 'randomforest':\n",
    "            self.randomforest(*args, **kwargs)\n",
    "        elif self.modelname == 'lightgbm':\n",
    "            self.lgbm(*args, **kwargs)\n",
    "            \n",
    "    def result(self):\n",
    "        Report = Myreport()\n",
    "        self.pcrc = Report.report(y_true=self.y_test, y_predict=self.y_pred, classNames=['-1','0','1'])\n",
    "        self.confusion = Report.confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b4422b16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF\n",
      "Class Name\t\tprecision\t\trecall\t\tf1-score\n",
      "-1   \t\t\t0.05   \t\t\t0.92   \t\t\t0.09\n",
      "0   \t\t\t0.97   \t\t\t0.31   \t\t\t0.47\n",
      "1   \t\t\tnan   \t\t\t0.00   \t\t\tnan\n",
      "accuracy is 0.33\n",
      "[[ 12. 239.   2.]\n",
      " [  1. 107.   2.]\n",
      " [  0.   0.   0.]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sherly\\AppData\\Local\\Temp\\ipykernel_11604\\3259504365.py:14: RuntimeWarning: invalid value encountered in divide\n",
      "  return self.confusion.diagonal() / np.sum(self.confusion, axis=1)\n"
     ]
    }
   ],
   "source": [
    "# 示例\n",
    "# random forest\n",
    "label5rf = Datamodel(data_name='label',model_name='randomforest')\n",
    "label5rf.data_read(path='D:/self_file/2303SW/230413/IF2303.csv',label='label_next5')\n",
    "label5rf.sample_balance()\n",
    "label5rf.data_split()\n",
    "\n",
    "label5rf.model_fit(n_estimator=500)\n",
    "label5rf.result()\n",
    "\n",
    "print('RF')\n",
    "print(label5rf.pcrc)\n",
    "print(label5rf.confusion)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
